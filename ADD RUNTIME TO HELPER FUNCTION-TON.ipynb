{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df047623",
   "metadata": {},
   "source": [
    "Helper function (NO cross validation and hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18977f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function which fit classification algoritham, evaluate and visualise model using train test split\n",
    "\n",
    "# Import evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "\n",
    "# Defining function\n",
    "def classification_model(X_train, X_test, y_train, y_test, clf, scaler):\n",
    "    \"\"\"\n",
    "    function fit the algorithm on the training set, evaluate the model, and visualise evaluation metrics\n",
    "    \"\"\"\n",
    "    ## Apply scaler\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    ## Fit the model using training dataset\n",
    "    start = time.time()\n",
    "    model=clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(model)\n",
    "    print('=='*45)\n",
    "\n",
    "    ## Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    ## Evaluate the model\n",
    "    print('Training set evaluation result :\\n')\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    precision_train = precision_score(y_train, y_train_pred)\n",
    "    recall_train = recall_score(y_train, y_train_pred)\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    roc_auc_score_train=roc_auc_score(y_train, y_train_pred)\n",
    "    runtime = end - start\n",
    "    print(\"Confusion Matrix: \\n\", cm_train)\n",
    "    print(\"Accuracy: \", accuracy_train)\n",
    "    print(\"Precision: \", precision_train)\n",
    "    print(\"Recall: \", recall_train)\n",
    "    print(\"F1 Score: \", f1_train)\n",
    "    print(\"roc_auc_score: \", roc_auc_score_train)\n",
    "    print(\"runtime: \", runtime)\n",
    "    print('\\n-------------------------------\\n')\n",
    "    print('Test set evaluation result :\\n')\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    precision_test = precision_score(y_test, y_test_pred)\n",
    "    recall_test = recall_score(y_test, y_test_pred)\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "    roc_auc_score_test=roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"Confusion Matrix: \\n\", cm_test)\n",
    "    print(\"Accuracy: \", accuracy_test)\n",
    "    print(\"Precision: \", precision_test)\n",
    "    print(\"Recall: \", recall_test)\n",
    "    print(\"F1 Score: \", f1_test)\n",
    "    print(\"roc_auc_score: \", roc_auc_score_test)\n",
    "    print('=='*45)\n",
    "\n",
    "    ## Visualizes evaluation metrics\n",
    "    fig,axes = plt.subplots(nrows=2, ncols=2)\n",
    "    ax1 = sns.heatmap(cm_train, annot=True, ax=axes[0,0], fmt='d')\n",
    "    ax1.set_title('Confusion Matrix for training set')\n",
    "    ax1.set_ylabel('True label')\n",
    "    ax1.set_xlabel('Predicted label')\n",
    "    ax2 = sns.heatmap(cm_test, annot=True, ax=axes[0,1], fmt='d')\n",
    "    ax2.set_title('Confusion Matrix for test set')\n",
    "    ax2.set_ylabel('True label')\n",
    "    ax2.set_xlabel('Predicted label')\n",
    "    ax3 = sns.barplot(x=['Accuracy', 'Precision', 'Recall', 'F1','roc_auc_score'], y=[accuracy_train, precision_train, recall_train, f1_train, roc_auc_score_train], ax=axes[1,0])\n",
    "    ax3.set_title('Evaluation Metrics for training set')\n",
    "    ax3.tick_params(axis='x', rotation=90)\n",
    "    ax4 = sns.barplot(x=['Accuracy', 'Precision', 'Recall', 'F1','roc_auc_score'], y=[accuracy_test, precision_test, recall_test, f1_test, roc_auc_score_test], ax=axes[1,1])\n",
    "    ax4.set_title('Evaluation Metrics for test set')\n",
    "    ax4.tick_params(axis='x', rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('=='*45)\n",
    "\n",
    "    return {'model': model, 'y_train_pred': y_train_pred, 'y_test_pred': y_test_pred, 'cm_test': cm_test, 'accuracy_test': accuracy_test,\n",
    "            'precision_test': precision_test, 'recall_test': recall_test, 'f1_test': f1_test, 'roc_auc_score_test': roc_auc_score_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d33f5ff",
   "metadata": {},
   "source": [
    "Helper function with cross validation and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f445aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function which fit classification algoritham using GridSearchCV, evaluate and visualise model\n",
    "\n",
    "# Import necessary dependancy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Defining function\n",
    "def classification_CV_model(X_train, X_test, y_train, y_test, clf, param_grid):\n",
    "    \"\"\"\n",
    "    function fit the algorithm using GridSearchCV on the training set, evaluate the model, and visualise evaluation metrics\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    ## Fit the model on training dataset\n",
    "    classifier = clf\n",
    "    model = GridSearchCV(classifier, param_grid, verbose=1, scoring='accuracy', cv=fold, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(model)\n",
    "    print('=='*45)\n",
    "    \n",
    "    # Print the best parameters and score\n",
    "    print(\"Best parameters:\", model.best_params_)\n",
    "    print(\"Best score:\", model.best_score_)\n",
    "    print('=='*45)\n",
    "    \n",
    "    ## Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    ## Evaluate the model\n",
    "    print('Training set evaluation result :\\n')\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    precision_train = precision_score(y_train, y_train_pred)\n",
    "    recall_train = recall_score(y_train, y_train_pred)\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    roc_auc_score_train=roc_auc_score(y_train, y_train_pred)\n",
    "    runtime = end - start \n",
    "    print(\"Confusion Matrix: \\n\", cm_train)\n",
    "    print(\"Accuracy: \", accuracy_train)\n",
    "    print(\"Precision: \", precision_train)\n",
    "    print(\"Recall: \", recall_train)\n",
    "    print(\"F1 Score: \", f1_train)\n",
    "    print(\"roc_auc_score: \", roc_auc_score_train)\n",
    "    print(\"runtime: \", runtime)\n",
    "    print('\\n-------------------------------\\n')\n",
    "    print('Test set evaluation result :\\n')\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    precision_test = precision_score(y_test, y_test_pred)\n",
    "    recall_test = recall_score(y_test, y_test_pred)\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "    roc_auc_score_test=roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"Confusion Matrix: \\n\", cm_test)\n",
    "    print(\"Accuracy: \", accuracy_test)\n",
    "    print(\"Precision: \", precision_test)\n",
    "    print(\"Recall: \", recall_test)\n",
    "    print(\"F1 Score: \", f1_test)\n",
    "    print(\"roc_auc_score: \", roc_auc_score_test)\n",
    "    print('=='*45)\n",
    "    \n",
    "    ## Visualizes evaluation metrics\n",
    "    fig,axes = plt.subplots(nrows=2, ncols=2)\n",
    "    ax1 = sns.heatmap(cm_train, annot=True, ax=axes[0,0], fmt='d')\n",
    "    ax1.set_title('Confusion Matrix for training set')\n",
    "    ax1.set_ylabel('True label')\n",
    "    ax1.set_xlabel('Predicted label')\n",
    "    ax2 = sns.heatmap(cm_test, annot=True, ax=axes[0,1], fmt='d')\n",
    "    ax2.set_title('Confusion Matrix for test set')\n",
    "    ax2.set_ylabel('True label')\n",
    "    ax2.set_xlabel('Predicted label')\n",
    "    ax3 = sns.barplot(x=['Accuracy', 'Precision', 'Recall', 'F1','roc_auc_score'], y=[accuracy_train, precision_train, recall_train, f1_train, roc_auc_score_train], ax=axes[1,0])\n",
    "    ax3.set_title('Evaluation Metrics for training set')\n",
    "    ax3.tick_params(axis='x', rotation=90)\n",
    "    ax4 = sns.barplot(x=['Accuracy', 'Precision', 'Recall', 'F1','roc_auc_score'], y=[accuracy_test, precision_test, recall_test, f1_test, roc_auc_score_test], ax=axes[1,1])\n",
    "    ax4.set_title('Evaluation Metrics for test set')\n",
    "    ax4.tick_params(axis='x', rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('=='*45)\n",
    "    \n",
    "    return {'model': model, 'y_train_pred': y_train_pred, 'y_test_pred': y_test_pred, 'cm_test': cm_test, 'accuracy_test': accuracy_test, \n",
    "            'precision_test': precision_test, 'recall_test': recall_test, 'f1_test': f1_test, 'roc_auc_score_test': roc_auc_score_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74b17e",
   "metadata": {},
   "source": [
    "FINAL TABLE FOR EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9cd8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating dataframe of performance of all models\n",
    "\n",
    "# Data\n",
    "model=['Logistic_Regression','Decision_Tree','Random_Forest','XGBoost','K_Nearest_Neighbor','Naive_Bayes','Support_Vector_Machine','ADABoost']\n",
    "Accuracy=[lr_cv['accuracy_test'],dt_cv['accuracy_test'],rf_cv['accuracy_test'],xgb_cv['accuracy_test'],knn_cv['accuracy_test'],nb_cv['accuracy_test'],svm_cv['accuracy_test'],adb_cv['accuracy_test']]\n",
    "Precision=[lr_cv['precision_test'],dt_cv['precision_test'],rf_cv['precision_test'],xgb_cv['precision_test'],knn_cv['precision_test'],nb_cv['precision_test'],svm_cv['precision_test'],adb_cv['precision_test']]\n",
    "Recall=[lr_cv['recall_test'],dt_cv['recall_test'],rf_cv['recall_test'],xgb_cv['recall_test'],knn_cv['recall_test'],nb_cv['recall_test'],svm_cv['recall_test'],adb_cv['recall_test']]\n",
    "F1_score=[lr_cv['f1_test'],dt_cv['f1_test'],rf_cv['f1_test'],xgb_cv['f1_test'],knn_cv['f1_test'],nb_cv['f1_test'],svm_cv['f1_test'],adb_cv['f1_test']]\n",
    "roc_auc_score=[lr_cv['roc_auc_score_test'],dt_cv['roc_auc_score_test'],rf_cv['roc_auc_score_test'],xgb_cv['roc_auc_score_test'],knn_cv['roc_auc_score_test'],nb_cv['roc_auc_score_test'],svm_cv['roc_auc_score_test'],adb_cv['roc_auc_score_test']]\n",
    "confusion_matrix=[lr_cv['cm_test'],dt_cv['cm_test'],rf_cv['cm_test'],xgb_cv['cm_test'],knn_cv['cm_test'],nb_cv['cm_test'],svm_cv['cm_test'],adb_cv['cm_test']]\n",
    "runtime=[lr_cv['runtime'],dt_cv['runtime'],rf_cv['runtime'],xgb_cv['runtime'],knn_cv['runtime'],nb_cv['runtime'],svm_cv['runtime'],adb_cv['runtime']]\n",
    "\n",
    "len(Accuracy)\n",
    "# Create a dataframe\n",
    "models_evaluation_df = pd.DataFrame({'model': model, 'Accuracy': Accuracy, 'Precision': Precision,\n",
    "                                     'Recall':Recall, 'F1_score':F1_score,\n",
    "                                     'roc_auc_score':roc_auc_score, 'confusion matrix':confusion_matrix,\n",
    "                                     'run time':runtime})\n",
    "# Dataframe\n",
    "models_evaluation_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
